#!/bin/sh
# 9999-zfs-autoinstall - live-config hook for unattended ZFS-on-root install
#
# Runs inside the Debian LIVE environment at boot.
# Triggered ONLY when kernel cmdline contains: zfs-auto-install=1
#
# It will:
#   - Wipe the target disk
#   - Create GPT with ESP + ZFS partition
#   - Create and mount ZFS pool/datasets
#   - debootstrap Debian 13 into ZFS root
#   - Install GRUB/EFI and configure root=ZFS=...
#
# WARNING: This DESTROYS the target disk.

set -eu

LOG_DIR="/var/log"
LOG_FILE="$LOG_DIR/zfs-autoinstall.log"
mkdir -p "$LOG_DIR"
# Log everything
exec >"$LOG_FILE" 2>&1

echo "[INFO] 9999-zfs-autoinstall starting"

MARKER="/run/zfs-autoinstall-done"
if [ -e "$MARKER" ]; then
    echo "[INFO] Autoinstall already completed once; skipping."
    exit 0
fi

CMDLINE="$(cat /proc/cmdline)"

# ---------------------------------------------------------------------------
# helpers: cmdline parsing
# ---------------------------------------------------------------------------
get_arg() {
    # get_arg name default
    name="$1"
    default="$2"
    for w in $CMDLINE; do
        case "$w" in
            "$name"=*)
                echo "${w#*=}"
                return 0
                ;;
        esac
    done
    echo "$default"
}

has_flag() {
    # has_flag name -> 0 if present, 1 if not
    name="$1"
    for w in $CMDLINE; do
        case "$w" in
            "$name"|"${name}"=1)
                return 0
                ;;
        esac
    done
    return 1
}

# ---------------------------------------------------------------------------
# Only run when armed with zfs-auto-install=1
# ---------------------------------------------------------------------------
if ! has_flag "zfs-auto-install"; then
    echo "[INFO] Kernel cmdline missing zfs-auto-install=1; skipping."
    exit 0
fi

echo "[INFO] zfs-auto-install=1 present, proceeding with destructive install."

# ---------------------------------------------------------------------------
# Defaults (must match zfs-live/env.sh where reasonable)
# ---------------------------------------------------------------------------

# Detect Debian codename from live system, fallback to trixie
DEBIAN_SUITE="trixie"
if [ -r /etc/os-release ]; then
    # shellcheck disable=SC1091
    . /etc/os-release || true
    if [ -n "${VERSION_CODENAME:-}" ]; then
        DEBIAN_SUITE="$VERSION_CODENAME"
    fi
fi

TARGET_DISK="$(get_arg zfs-disk /dev/sda)"
POOL_NAME="$(get_arg zfs-pool rpool)"
ROOT_DATASET_NAME="$(get_arg zfs-rootds ROOT/${DEBIAN_SUITE})"
HOSTNAME_VAL="$(get_arg zfs-hostname debian-zfs)"
TIMEZONE_VAL="$(get_arg zfs-timezone Etc/UTC)"
USERNAME_VAL="$(get_arg zfs-user debian)"
PASSWORD_VAL="$(get_arg zfs-pass debian)"
NET_IFACE="$(get_arg zfs-net-if ens3)"

# Optional darksite toggle and data disks (future multi-disk support)
USE_DARKSITE="0"
if has_flag "zfs-use-darksite"; then
    USE_DARKSITE="1"
fi

DATA_DISKS_RAW="$(get_arg zfs-data-disks "")"

echo "[INFO] Using parameters:"
echo "  TARGET_DISK       = $TARGET_DISK"
echo "  POOL_NAME         = $POOL_NAME"
echo "  ROOT_DATASET_NAME = $ROOT_DATASET_NAME"
echo "  HOSTNAME          = $HOSTNAME_VAL"
echo "  TIMEZONE          = $TIMEZONE_VAL"
echo "  USERNAME          = $USERNAME_VAL"
echo "  NET_IFACE         = $NET_IFACE"
echo "  USE_DARKSITE      = $USE_DARKSITE"
echo "  DATA_DISKS_RAW    = $DATA_DISKS_RAW"

if [ ! -b "$TARGET_DISK" ]; then
    echo "[ERROR] Target disk $TARGET_DISK is not a block device."
    exit 1
fi

echo "[WARN] About to DESTROY all data on $TARGET_DISK in 10 seconds..."
sleep 10

# ---------------------------------------------------------------------------
# Ensure required commands exist
# ---------------------------------------------------------------------------
need_cmd() {
    c="$1"
    if ! command -v "$c" >/dev/null 2>&1; then
        echo "[ERROR] Missing required command: $c"
        exit 1
    fi
}

need_cmd sgdisk
need_cmd zpool
need_cmd zfs
need_cmd debootstrap
need_cmd grub-install
need_cmd mkfs.vfat
need_cmd modprobe

# ---------------------------------------------------------------------------
# Partitioning: GPT with ESP + ZFS
# ---------------------------------------------------------------------------
set -x

sgdisk --zap-all "$TARGET_DISK"

# Partition 1: EFI System Partition, 1MiBâ€“1GiB
sgdisk -n1:1M:+1G -t1:EF00 -c1:"EFI System Partition" "$TARGET_DISK"

# Partition 2: rest of disk for ZFS
sgdisk -n2:0:0   -t2:BF01 -c2:"ZFS root" "$TARGET_DISK"

# Re-read partition table
partprobe "$TARGET_DISK" || true
sleep 2

# Derive partition names. If disk ends with a digit (nvme0n1), use p1/p2.
case "$TARGET_DISK" in
    *[0-9])
        ESP_PART="${TARGET_DISK}p1"
        ZFS_PART="${TARGET_DISK}p2"
        ;;
    *)
        ESP_PART="${TARGET_DISK}1"
        ZFS_PART="${TARGET_DISK}2"
        ;;
esac

echo "[INFO] ESP partition : $ESP_PART"
echo "[INFO] ZFS partition : $ZFS_PART"

mkfs.vfat -F32 "$ESP_PART"

# ---------------------------------------------------------------------------
# Create ZFS pool and datasets
# ---------------------------------------------------------------------------
modprobe zfs

zpool create -f \
  -o ashift=12 \
  -o autotrim=on \
  -O compression=lz4 \
  -O acltype=posixacl \
  -O xattr=sa \
  -O dnodesize=auto \
  -O normalization=formD \
  -O relatime=on \
  -O canmount=off \
  -O mountpoint=/ \
  "$POOL_NAME" "$ZFS_PART"

# Create root and common datasets
zfs create -o canmount=off -o mountpoint=none "$POOL_NAME/ROOT"
zfs create -o canmount=noauto -o mountpoint=/ "$POOL_NAME/$ROOT_DATASET_NAME"

zfs create -o mountpoint=/home "$POOL_NAME/home"
zfs create -o mountpoint=/var "$POOL_NAME/var"
zfs create -o mountpoint=/var/log "$POOL_NAME/var/log"
zfs create -o mountpoint=/var/tmp "$POOL_NAME/var/tmp"
zfs create -o mountpoint=/tmp -o setuid=off "$POOL_NAME/tmp"

# Mount root dataset
TARGET_MNT="/mnt/target"
mkdir -p "$TARGET_MNT"

zfs mount "$POOL_NAME/$ROOT_DATASET_NAME"

# Now ensure mountpoints
mount -t zfs "$POOL_NAME/$ROOT_DATASET_NAME" "$TARGET_MNT"

mkdir -p "$TARGET_MNT/home" "$TARGET_MNT/var" "$TARGET_MNT/var/log" \
         "$TARGET_MNT/var/tmp" "$TARGET_MNT/tmp" "$TARGET_MNT/boot/efi"

mount -t zfs "$POOL_NAME/home"     "$TARGET_MNT/home"
mount -t zfs "$POOL_NAME/var"      "$TARGET_MNT/var"
mount -t zfs "$POOL_NAME/var/log"  "$TARGET_MNT/var/log"
mount -t zfs "$POOL_NAME/var/tmp"  "$TARGET_MNT/var/tmp"
mount -t zfs "$POOL_NAME/tmp"      "$TARGET_MNT/tmp"

mount "$ESP_PART" "$TARGET_MNT/boot/efi"

# ---------------------------------------------------------------------------
# Optional: copy darksite repo into target and add APT source
# ---------------------------------------------------------------------------
if [ "$USE_DARKSITE" = "1" ] && [ -d /opt/darksite ]; then
    echo "[INFO] Using darksite repo from /opt/darksite"
    mkdir -p "$TARGET_MNT/opt"
    cp -a /opt/darksite "$TARGET_MNT/opt/darksite"
    # We'll add a simple file in sources.list.d; user can customize later.
    mkdir -p "$TARGET_MNT/etc/apt/sources.list.d"
    cat >"$TARGET_MNT/etc/apt/sources.list.d/darksite.list" <<EOF_DARK
deb [trusted=yes] file:/opt/darksite ./
EOF_DARK
else
    echo "[INFO] No darksite configured or /opt/darksite missing; using network mirror."
fi

# ---------------------------------------------------------------------------
# debootstrap Debian into ZFS root
# ---------------------------------------------------------------------------
MIRROR_DEFAULT="http://deb.debian.org/debian"
MIRROR="$(get_arg zfs-mirror "$MIRROR_DEFAULT")"

echo "[INFO] Bootstrapping Debian suite '$DEBIAN_SUITE' from mirror: $MIRROR"
debootstrap \
  --include=linux-image-amd64,systemd-sysv,grub-efi-amd64,zfsutils-linux \
  "$DEBIAN_SUITE" "$TARGET_MNT" "$MIRROR"

# ---------------------------------------------------------------------------
# Basic system configuration inside chroot
# ---------------------------------------------------------------------------

# /etc/hostname
echo "$HOSTNAME_VAL" >"$TARGET_MNT/etc/hostname"

# /etc/hosts
cat >"$TARGET_MNT/etc/hosts" <<EOF_HOSTS
127.0.0.1   localhost
127.0.1.1   $HOSTNAME_VAL

::1         localhost ip6-localhost ip6-loopback
ff02::1     ip6-allnodes
ff02::2     ip6-allrouters
EOF_HOSTS

# Timezone
echo "$TIMEZONE_VAL" >"$TARGET_MNT/etc/timezone"
ln -sf "/usr/share/zoneinfo/$TIMEZONE_VAL" "$TARGET_MNT/etc/localtime"

# Simple network config: DHCP on user-specified interface
mkdir -p "$TARGET_MNT/etc/network"
cat >"$TARGET_MNT/etc/network/interfaces" <<EOF_NET
auto lo
iface lo inet loopback

allow-hotplug $NET_IFACE
iface $NET_IFACE inet dhcp
EOF_NET

# Ensure /tmp has correct perms
chmod 1777 "$TARGET_MNT/tmp" || true

# ---------------------------------------------------------------------------
# Prepare chroot mounts
# ---------------------------------------------------------------------------
mount --rbind /dev "$TARGET_MNT/dev"
mount --rbind /sys "$TARGET_MNT/sys"
mount -t proc /proc "$TARGET_MNT/proc"

# ---------------------------------------------------------------------------
# In-chroot configuration: users, ZFS, initramfs, GRUB
# ---------------------------------------------------------------------------
chroot "$TARGET_MNT" /bin/sh -eux <<EOF_CHROOT
# Set root and user passwords
echo "root:${PASSWORD_VAL}" | chpasswd

if ! id "$USERNAME_VAL" >/dev/null 2>&1; then
    useradd -m -s /bin/bash "$USERNAME_VAL"
fi
echo "${USERNAME_VAL}:${PASSWORD_VAL}" | chpasswd
# Add to sudo group if present
if getent group sudo >/dev/null 2>&1; then
    usermod -aG sudo "$USERNAME_VAL" || true
fi

# Enable ZFS in initramfs
if [ -f /etc/default/zfs ]; then
    if ! grep -q '^ZFS=' /etc/default/zfs; then
        echo 'ZFS=yes' >>/etc/default/zfs
    fi
else
    echo 'ZFS=yes' >/etc/default/zfs
fi

# Generate zpool.cache in /etc/zfs
mkdir -p /etc/zfs
# cachefile will be rewritten once we import, but ensure directory exists.
zpool set cachefile=/etc/zfs/zpool.cache "$POOL_NAME" || true

# Make sure ZFS tools and DKMS are installed (in case debootstrap missed anything)
export DEBIAN_FRONTEND=noninteractive
apt-get update || true
apt-get install -y --no-install-recommends zfs-initramfs zfsutils-linux || true

# Update initramfs for all kernels
if command -v update-initramfs >/dev/null 2>&1; then
    update-initramfs -u -k all
fi

# Configure GRUB to use root=ZFS=...
GRUB_DEFAULT_FILE="/etc/default/grub"
if [ -f "\$GRUB_DEFAULT_FILE" ]; then
    # Replace GRUB_CMDLINE_LINUX_DEFAULT or add it if missing
    if grep -q '^GRUB_CMDLINE_LINUX_DEFAULT=' "\$GRUB_DEFAULT_FILE"; then
        sed -i "s|^GRUB_CMDLINE_LINUX_DEFAULT=.*|GRUB_CMDLINE_LINUX_DEFAULT=\"root=ZFS=${POOL_NAME}/${ROOT_DATASET_NAME} quiet\"|" "\$GRUB_DEFAULT_FILE"
    else
        echo "GRUB_CMDLINE_LINUX_DEFAULT=\"root=ZFS=${POOL_NAME}/${ROOT_DATASET_NAME} quiet\"" >>"\$GRUB_DEFAULT_FILE"
    fi
fi

# Make sure grub has zfs integration
if ! dpkg -l | grep -q '^ii  grub-efi-amd64'; then
    apt-get install -y grub-efi-amd64 || true
fi
if ! dpkg -l | grep -q '^ii  grub2-common'; then
    apt-get install -y grub2-common || true
fi

# Enable ZFS services if systemd is present
if command -v systemctl >/dev/null 2>&1; then
    systemctl enable zfs-import-cache.service zfs-mount.service zfs-zed.service zfs.target || true
fi

# Regenerate GRUB config
if command -v update-grub >/dev/null 2>&1; then
    update-grub
elif command -v update-grub2 >/dev/null 2>&1; then
    update-grub2
fi
EOF_CHROOT

# ---------------------------------------------------------------------------
# Install GRUB (EFI)
# ---------------------------------------------------------------------------
# Use --target x86_64-efi and ESP at /boot/efi
chroot "$TARGET_MNT" grub-install \
  --target=x86_64-efi \
  --efi-directory=/boot/efi \
  --bootloader-id="debian" \
  --recheck

if chroot "$TARGET_MNT" command -v update-grub >/dev/null 2>&1; then
    chroot "$TARGET_MNT" update-grub
elif chroot "$TARGET_MNT" command -v update-grub2 >/dev/null 2>&1; then
    chroot "$TARGET_MNT" update-grub2
fi

# ---------------------------------------------------------------------------
# Cleanup chroot mounts
# ---------------------------------------------------------------------------
umount -lf "$TARGET_MNT/proc" || true
umount -lf "$TARGET_MNT/sys"  || true
umount -lf "$TARGET_MNT/dev"  || true
umount -lf "$TARGET_MNT/dev/pts" 2>/dev/null || true

# Leave ZFS pool mounted for now; reboot will re-import it.

set +x
touch "$MARKER"
echo "[INFO] ZFS autoinstall completed successfully; you can now reboot into the installed system."
exit 0

